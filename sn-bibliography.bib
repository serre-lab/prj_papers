@string{bmvc={Proceedings of the British Machine Vision Conference (BMVC)}}
@string{cviu={Computer Vision and Image Understanding (CVIU)}}
@string{cvpr={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}}
@string{eccv={Proceedings of the IEEE European Conference on Computer Vision (ECCV)}}
@string{iccv={Proceedings of the IEEE International Conference on Computer Vision (ICCV)}}
@string{iclr={Proceedings of the International Conference on Learning Representations (ICLR)}}
@string{wiclr={Workshop Proceedings of the International Conference on Learning Representations (ICLR)}}
@string{ijcv={International Journal of Computer Vision (IJCV)}}
@string{jmlr={The Journal of Machine Learning Research (JMLR)}}
@string{nips={Advances in Neural Information Processing Systems (NIPS)}}
@string{neurips={Advances in Neural Information Processing Systems (NeurIPS)}}
@string{tpami={IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)}}
@string{tnnls={IEEE Transactions on Neural Networks and Learning Systems (TNNLS)}}
@string{aaai={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)}}
@string{emnlp={Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)}}
@string{sigir={ACM Conference on Research and Development in Information Retrieval (SIGIR)}}
@string{icip={Proceedings of the IEEE International Conference on Image Processing (ICIP)}}
@string{naacl={Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)}}
@string{acl={Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)}}
@string{icml={Proceedings of the International Conference on Machine Learning (ICML)}}
@string{ijcai={Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)}}
@string{kdd={Proceedings of the International Conference on Knowledge Discovery and Data Mining (KDD)}}
@string{dsaa={Proceedings of the IEEE International Conference on data science and advanced analytics (DSAA)}}
@string{icde={IEEE International Conference Data Engineering (ICDE)}}
@string{jstars={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (JSTARS)}}
@string{springer={Springer International Publishing}}
@string{wacv={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}}

@string{arxiv = {{A}r{X}iv e-print}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Journal article
@article{bib1,
  author		= "Campbell, S. L. and Gear, C. W.",
  title			= "The index of general nonlinear {D}{A}{E}{S}",
  journal		= "Numer. {M}ath.",
  volume		= "72",
  number		= "2",
  pages			= "173--196",
  year			= "1995"
}
@misc{kirillov2023segment,
      title={Segment Anything}, 
      author={Alexander Kirillov and Eric Mintun and Nikhila Ravi and Hanzi Mao and Chloe Rolland and Laura Gustafson and Tete Xiao and Spencer Whitehead and Alexander C. Berg and Wan-Yen Lo and Piotr Dollár and Ross Girshick},
      year={2023},
      eprint={2304.02643},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{craft,
      title={CRAFT: Concept Recursive Activation FacTorization for Explainability}, 
      author={Fel, Thomas and Agustin, Picard and Louis, Bethune and Thibaut, Boissin and David, Vigouroux and Julien, Colin and Rémi, Cadène and Thomas, Serre},
      year={2023},
      booktitle=cvpr,
}

@inproceedings{holistic,
  title={A Holistic Approach to Unifying Automatic Concept Extraction and Concept Importance Estimation},
  author={Fel, Thomas and Boutin, Victor and Moayeri, Mazda and Cad{\`e}ne, R{\'e}mi and Bethune, Louis and Chalvidal, Mathieu and Serre, Thomas and others},
  journal=neurips,
  year={2023}
}

@inproceedings{maco,
  title         = {Unlocking Feature Visualization for Deeper Networks with 
                  MAgnitude Constrained Optimization},
  author        = {Thomas Fel and Thibaut Boissin and Victor Boutin and Agustin Picard and
                  Paul Novello and Julien Colin and Drew Linsley and Tom Rousseau and
                  Rémi Cadène and Laurent Gardes, Thomas Serre},
  journal       = neurips,
  year          = {2023}
}

@article{wilf2021dataset,
	abstract = {Leaves are the most abundant and visible plant organ, both in the modern world and the fossil record. Identifying foliage to the correct plant family based on leaf architecture is a fundamental botanical skill that is also critical for isolated fossil leaves, which often, especially in the Cenozoic, represent extinct genera and species from extant families. Resources focused on leaf identification are remarkably scarce; however, the situation has improved due to the recent proliferation of digitized herbarium material, live-plant identification applications, and online collections of cleared and fossil leaf images. Nevertheless, the need remains for a specialized image dataset for comparative leaf architecture. We address this gap by assembling an open-access database of 30,252 images of vouchered leaf specimens vetted to family level, primarily of angiosperms, including 26,176 images of cleared and x-rayed leaves representing 354 families and 4,076 of fossil leaves from 48 families. The images maintain original resolution, have user-friendly filenames, and are vetted using APG and modern paleobotanical standards. The cleared and x-rayed leaves include the Jack A. Wolfe and Leo J. Hickey contributions to the National Cleared Leaf Collection and a collection of high-resolution scanned x-ray negatives, housed in the Division of Paleobotany, Department of Paleobiology, Smithsonian National Museum of Natural History, Washington D.C.; and the Daniel I. Axelrod Cleared Leaf Collection, housed at the University of California Museum of Paleontology, Berkeley. The fossil images include a sampling of Late Cretaceous to Eocene paleobotanical sites from the Western Hemisphere held at numerous institutions, especially from Florissant Fossil Beds National Monument (late Eocene, Colorado), as well as several other localities from the Late Cretaceous to Eocene of the Western USA and the early Paleogene of Colombia and southern Argentina. The dataset facilitates new research and education opportunities in paleobotany, comparative leaf architecture, systematics, and machine learning.},
	author = {Peter Wilf and Scott L. Wing and Herbert W. Meyer and Jacob A. Rose and Rohit Saha and Thomas Serre and N.Rub{\'e}n C{\'u}neo and Michael P. Donovan and Diane M. Erwin and Maria A. Gandolfo and Erika Gonzalez-Akre and Fabiany Herrera and Shusheng Hu and Ari Iglesias and Kirk R. Johnson and Talia S. Karim and Xiaoyu Zou},
	doi = {10.3897/phytokeys.187.72350},
	eprint = {https://doi.org/10.3897/phytokeys.187.72350},
	issn = {1314-2011},
	journal = {PhytoKeys},
	pages = {93-128},
	publisher = {Pensoft Publishers},
	title = {An image dataset of cleared, x-rayed, and fossil leaves vetted to plant family for human and machine learning},
	url = {https://doi.org/10.3897/phytokeys.187.72350},
	volume = {187},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.3897/phytokeys.187.72350}}


@article{
wilf2016leaves,
author = {Peter Wilf  and Shengping Zhang  and Sharat Chikkerur  and Stefan A. Little  and Scott L. Wing  and Thomas Serre },
title = {Computer vision cracks the leaf code},
journal = {Proceedings of the National Academy of Sciences},
volume = {113},
number = {12},
pages = {3305-3310},
year = {2016},
doi = {10.1073/pnas.1524473113},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1524473113},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1524473113},
abstract = {Understanding the extremely variable, complex shape and venation characters of angiosperm leaves is one of the most challenging problems in botany. Machine learning offers opportunities to analyze large numbers of specimens, to discover novel leaf features of angiosperm clades that may have phylogenetic significance, and to use those characters to classify unknowns. Previous computer vision approaches have primarily focused on leaf identification at the species level. It remains an open question whether learning and classification are possible among major evolutionary groups such as families and orders, which usually contain hundreds to thousands of species each and exhibit many times the foliar variation of individual species. Here, we tested whether a computer vision algorithm could use a database of 7,597 leaf images from 2,001 genera to learn features of botanical families and orders, then classify novel images. The images are of cleared leaves, specimens that are chemically bleached, then stained to reveal venation. Machine learning was used to learn a codebook of visual elements representing leaf shape and venation patterns. The resulting automated system learned to classify images into families and orders with a success rate many times greater than chance. Of direct botanical interest, the responses of diagnostic features can be visualized on leaf images as heat maps, which are likely to prompt recognition and evolutionary interpretation of a wealth of novel morphological characters. With assistance from computer vision, leaves are poised to make numerous new contributions to systematic and paleobotanical studies.}}
@book{mcginitie1953fossil,
  title={Fossil Plants of the Florissant Beds, Colorado},
  author={McGinitie, H.D.},
  lccn={a53008185},
  series={Carnegie Institution of Washington publication},
  url={https://books.google.com/books?id=Ge-EzQEACAAJ},
  year={1953},
  publisher={Carnegie Institution of Washington}
}
@misc{herbarium-2022-fgvc9,
    author = {Brendan Hogan and damon and inversion and John Park and Riccardo de Lutio},
    title = {Herbarium 2022 - FGVC9},
    year = {2022},
    howpublished = {\url{https://kaggle.com/competitions/herbarium-2022-fgvc9}},
    note = {Kaggle}
}
@incollection{Wilf2008FossilLeaves,
  author       = {Peter Wilf},
  title        = {Fossil angiosperm leaves: paleobotany’s difficult children prove themselves},
  booktitle    = {From Evolution to Geobiology: Research Questions Driving Paleontology at the Start of a New Century},
  series       = {Paleontological Society Papers},
  volume       = {14},
  editor       = {Patricia H. Kelley and Richard K. Bambach},
  pages        = {320--333},
  year         = {2008},
  publisher    = {The Paleontological Society},
  note         = {Paleontological Society Short Course, October 4 2008}
}

@article{Geirhos2020Shortcuts,
  title   = {Shortcut Learning in Deep Neural Networks},
  author  = {Geirhos, Robert and Jacobsen, J{\"o}rn-Henrik and Michaelis, Claudio 
             and Zemel, Richard S. and Brendel, Wieland and Bethge, Matthias 
             and Wichmann, Felix A.},
  journal = {Nature Machine Intelligence},
  volume  = {2},
  number  = {11},
  pages   = {665--673},
  year    = {2020},
  doi     = {10.1038/s42256-020-00257-z}
}

@inproceedings{Hermann2024Foundations,
  title     = {On the Foundations of Shortcut Learning},
  author    = {Hermann, Katherine L. and Mobahi, Hossein and Fel, Thomas and 
               Mozer, Michael C.},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
  year      = {2024},
  note      = {ICLR 2024 (spotlight paper), arXiv:2310.16228}
}

@article{Brown2023ShortcutTesting,
  title   = {Detecting shortcut learning for fair medical AI using shortcut testing},
  author  = {Brown, Alexander and Toma{\v{s}}ev, Nenad and Freyberg, Jan and Liu, 
             Yuan and Karthikesalingam, Alan and Schrouff, Jessica},
  journal = {Nature Communications},
  volume  = {14},
  pages   = {4314},
  year    = {2023},
  doi     = {10.1038/s41467-023-39902-7}
}

@article{Lin2024ShortcutSegmentation,
  title   = {Shortcut Learning in Medical Image Segmentation},
  author  = {Lin, Manxi and Weng, Nina and Mikolaj, Kamil and Bashir, Zahra and 
             S{\o}ndergaard Svendsen, Morten Bo and Tolsgaard, Martin and 
             Christensen, Anders Nymark and Feragen, Aasa},
  journal = {arXiv preprint arXiv:2403.06748},
  year    = {2024},
  note    = {Accepted at MICCAI 2024}
}

@article{Nauta2022SkinShortcut,
  title   = {Uncovering and Correcting Shortcut Learning in Machine Learning 
             Models for Skin Cancer Diagnosis},
  author  = {Nauta, Meike and Walsh, Ricky and Dubowski, Adam and Seifert, Christin},
  journal = {Diagnostics},
  volume  = {12},
  number  = {1},
  pages   = {40},
  year    = {2022},
  doi     = {10.3390/diagnostics12010040}
}

@article{Hill2024ShortcutRisk,
  title   = {The risk of shortcutting in deep learning algorithms for medical imaging research},
  author  = {Hill, Brandon G. and Koback, Frances L. and Schilling, Peter L.},
  journal = {Scientific Reports},
  volume  = {14},
  pages   = {29224},
  year    = {2024},
  doi     = {10.1038/s41598-024-79838-6}
}


@INPROCEEDINGS{plantclassificationGunjal2024,
  author={Gunjal, Monica and Thorat, Amruta and Londhe, Gayatri and Kamble, Ankit and Gholap, Chinmayee and Patil, Prerana},
  booktitle={2024 Ninth International Conference on Science Technology Engineering and Mathematics (ICONSTEM)}, 
  title={Plant Species Classification Using Deep Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  keywords={Training;Accuracy;Computational modeling;Plants (biology);Forestry;Classification algorithms;Convolutional neural networks;Plant species classification;Convolutional Neural Networks;Random Forest;image recognition;deep learning;dataset preprocessing;model training;accuracy assessment},
  doi={10.1109/ICONSTEM60960.2024.10568579}}

@article{machinelearningspecies,
author = {Wäldchen, Jana and Mäder, Patrick},
title = {Machine learning for image based species identification},
journal = {Methods in Ecology and Evolution},
volume = {9},
number = {11},
pages = {2216-2225},
keywords = {automated species identification, computer vision, convolutional neural network, deep learning, images},
doi = {https://doi.org/10.1111/2041-210X.13075},
url = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13075},
eprint = {https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13075},
abstract = {Abstract Accurate species identification is the basis for all aspects of taxonomic research and is an essential component of workflows in biological research. Biologists are asking for more efficient methods to meet the identification demand. Smart mobile devices, digital cameras as well as the mass digitisation of natural history collections led to an explosion of openly available image data depicting living organisms. This rapid increase in biological image data in combination with modern machine learning methods, such as deep learning, offers tremendous opportunities for automated species identification. In this paper, we focus on deep learning neural networks as a technology that enabled breakthroughs in automated species identification in the last 2 years. In order to stimulate more work in this direction, we provide a brief overview of machine learning frameworks applicable to the species identification problem. We review selected deep learning approaches for image based species identification and introduce publicly available applications. Eventually, this article aims to provide insights into the current state-of-the-art in automated identification and to serve as a starting point for researchers willing to apply novel machine learning techniques in their biological studies. While modern machine learning approaches only slowly pave their way into the field of species identification, we argue that we are going to see a proliferation of these techniques being applied to the problem in the future. Artificial intelligence systems will provide alternative tools for taxonomic identification in the near future.},
year = {2018}
}

@article{resnetHe2015,
  author       = {Kaiming He and
                  Xiangyu Zhang and
                  Shaoqing Ren and
                  Jian Sun},
  title        = {Deep Residual Learning for Image Recognition},
  journal      = {CoRR},
  volume       = {abs/1512.03385},
  year         = {2015},
  url          = {http://arxiv.org/abs/1512.03385},
  eprinttype    = {arXiv},
  eprint       = {1512.03385},
  timestamp    = {Wed, 25 Jan 2023 11:01:16 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@book{florissant,
author = {Meyer, Herbert},
year = {2003},
month = {01},
pages = {},
title = {The Fossils of Florissant},
isbn = {1-58834-107-0}
}
@inproceedings{taha2020triplet,
title = "Boosting standard classification architectures through a ranking regularizer",
abstract = "We employ triplet loss as a feature embedding regularizer to boost classification performance. Standard architectures, like ResNet and Inception, are extended to support both losses with minimal hyper-parameter tuning. This promotes generality while fine-tuning pretrained networks. Triplet loss is a powerful surrogate for recently proposed embedding regularizers. Yet, it is avoided due to large batch-size requirement and high computational cost. Through our experiments, we re-assess these assumptions.During inference, our network supports both classification and embedding tasks without any computational overhead. Quantitative evaluation highlights a steady improvement on five fine-grained recognition datasets. Further evaluation on an imbalanced video dataset achieves significant improvement. Triplet loss brings feature embedding capabilities like nearest neighbor to classification models. Code available at http://bit.ly/2LNYEqL.",
author = "Ahmed Taha and Yi-Ting Chen and Teruhisa Misu and Abhinav Shrivastava and Larry Davis",
note = "Publisher Copyright: {\textcopyright} 2020 IEEE.; 2020 IEEE/CVF Winter Conference on Applications of Computer Vision, WACV 2020 ; Conference date: 01-03-2020 Through 05-03-2020",
year = "2020",
month = mar,
doi = "10.1109/WACV45572.2020.9093279",
language = "English",
series = "Proceedings - 2020 IEEE Winter Conference on Applications of Computer Vision, WACV 2020",
publisher = "Institute of Electrical and Electronics Engineers Inc.",
pages = "747--755",
booktitle = "Proceedings - 2020 IEEE Winter Conference on Applications of Computer Vision, WACV 2020",
address = "United States",
}

@inproceedings{
bao2022beit,
title={{BE}iT: {BERT} Pre-Training of Image Transformers},
author={Hangbo Bao and Li Dong and Songhao Piao and Furu Wei},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=p-BhZSz59o4}
}
@misc{zhang2023adding,
      title={Adding Conditional Control to Text-to-Image Diffusion Models}, 
      author={Lvmin Zhang and Anyi Rao and Maneesh Agrawala},
      year={2023},
      eprint={2302.05543},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{RISE2018,
      title={RISE: Randomized Input Sampling for Explanation of Black-box Models}, 
      author={Vitali Petsiuk and Abir Das and Kate Saenko},
      year={2018},
      eprint={1806.07421},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1806.07421}, 
}

@article{Selvaraju_2019,
   title={Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization},
   volume={128},
   ISSN={1573-1405},
   url={http://dx.doi.org/10.1007/s11263-019-01228-7},
   DOI={10.1007/s11263-019-01228-7},
   number={2},
   journal={International Journal of Computer Vision},
   publisher={Springer Science and Business Media LLC},
   author={Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
   year={2019},
   month=oct, pages={336–359} 
}

@article{fel2022xplique,
  title={Xplique: A Deep Learning Explainability Toolbox},
  author={Fel, Thomas and Hervier, Lucas and Vigouroux, David and Poche, Antonin and Plakoo, Justin and Cadene, Remi and Chalvidal, Mathieu and Colin, Julien and Boissin, Thibaut and Bethune, Louis and Picard, Agustin and Nicodeme, Claire 
          and Gardes, Laurent and Flandin, Gregory and Serre, Thomas},
  journal={Workshop on Explainable Artificial Intelligence for Computer Vision (CVPR)},
  year={2022}
}


%% Journal article with DOI
@article{bib2,
  author		= "Slifka, M. K. and Whitton, J. L.",
  title			= "Clinical implications of dysregulated cytokine production",
  journal		= "J. {M}ol. {M}ed.",
  volume		= "78",
  pages			= "74--80",
  year			= "2000",
  doi			= "10.1007/s001090000086"
}

%% Journal article
@article{bib3,
  author		= "Hamburger, C.",
  title			= "Quasimonotonicity, regularity and duality for nonlinear systems of 
					partial differential equations",
  journal		= "Ann. Mat. Pura. Appl.",
  volume		= "169",
  number		= "2",
  pages			= "321--354",
  year			= "1995"
}

%% book, authored
@book{bib4,
  author		= "Geddes, K. O. and Czapor, S. R. and Labahn, G.",
  title			= "Algorithms for {C}omputer {A}lgebra",
  address		= "Boston",
  publisher		= "Kluwer",
  year			= "1992"
}

%% Item 8. Book, chapter
@incollection{bib5,
  author		= "Broy, M.",
  title			= "Software engineering---from auxiliary to key technologies",
  editor		= "Broy, M. and Denert, E.",
  booktitle		= "Software Pioneers",
  pages			= "10--13",
  address		= "New {Y}ork",
  publisher		= "Springer",
  year			= "1992"
}

%% Book, edited
@book{bib6,
  editor		= "Seymour, R. S.",
  title			= "Conductive {P}olymers",
  address		= "New {Y}ork",
  publisher		= "Plenum",
  year			= "1981"
}

%% Chapter in a book in a series with volume titles
@inproceedings{bib7,
  author		= "Smith, S. E.",
  title			= "Neuromuscular blocking drugs in man",
  editor		= "Zaimis, E.",
  volume		= "42",
  booktitle		= "Neuromuscular junction. {H}andbook of experimental pharmacology",
  pages			= "593--660",
  address		= "Heidelberg",
  publisher		= "Springer",
  year			= "1976"
}

%% Paper presented at a conference
@misc{bib8,
  author		= "Chung, S. T. and Morris, R. L.",
  title			= "Isolation and characterization of plasmid deoxyribonucleic acid from 
					Streptomyces fradiae",
  year			= "1978",
  note			= "Paper presented at the 3rd international symposium on the genetics 
					of industrial microorganisms, University of {W}isconsin, {M}adison, 
					4--9 June 1978"
}

%% Data citation example
@misc{bib9,
  author		= "Hao, Z. and AghaKouchak, A. and Nakhjiri, N. and Farahmand, A.",
  title			= "Global integrated drought monitoring and prediction system (GIDMaPS) data sets", 
  year			= "2014",
  note			= "figshare \url{https://doi.org/10.6084/m9.figshare.853801}"
}

%% Preprint citation example
@misc{bib10, 
  author		= "Babichev, S. A. and Ries, J. and Lvovsky, A. I.",
  title			= "Quantum scissors: teleportation of single-mode optical states by means 
					of a nonlocal single photon", 
  year			= "2002",
  note			= "Preprint at \url{https://arxiv.org/abs/quant-ph/0208066v1}"
}

@article{bib11,
  author		= "Beneke, M. and Buchalla, G. and Dunietz, I.",
  title			= "Mixing induced {CP} asymmetries in inclusive {B} decays",
  journal		= "Phys. {L}ett.",
  volume		= "B393",
  year			= "1997",
  pages			= "132-142",
  archivePrefix		= "arXiv",
  eprint		= "0707.3168",
  primaryClass		= "gr-gc"
}

@softmisc{bib12,
  author		= "Stahl, B.",
  title			= "deep{SIP}: deep learning of {S}upernova {I}a {P}arameters",
  version		= "0.42",
  keywords		= "Software",
  howpublished		= "Astrophysics {S}ource {C}ode {L}ibrary",
  year			= "2020",
  month			= "Jun",
  eid			= "ascl:2006.023",
  pages			= "ascl:2006.023",
  archivePrefix		= "ascl",
  eprint		= "2006.023",
  adsurl		= "{https://ui.adsabs.harvard.edu/abs/2020ascl.soft06023S}",
  adsnote		= "Provided by the SAO/NASA Astrophysics Data System"
}

@inproceedings{CycleGAN2017,
  title={Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  booktitle={Computer Vision (ICCV), 2017 IEEE International Conference on},
  year={2017}
}


@inproceedings{isola2017image,
  title={Image-to-Image Translation with Conditional Adversarial Networks},
  author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on},
  year={2017}
}

@misc{taha2020boosting,
      title={Boosting Standard Classification Architectures Through a Ranking Regularizer}, 
      author={Ahmed Taha and Yi-Ting Chen and Teruhisa Misu and Abhinav Shrivastava and Larry Davis},
      year={2020},
      eprint={1901.08616},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{baek2019character,
  title={Character region awareness for text detection},
  author={Baek, Youngmin and Lee, Bado and Han, Dongyoon and Yun, Sangdoo and Lee, Hwalsuk},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9365--9374},
  year={2019}
}
@article{spagnuolo22,
author = {Spagnuolo, Edward and Wilf, Peter and Serre, Thomas},
year = {2022},
month = {03},
pages = {},
title = {Decoding family-level features for modern and fossil leaves from computer-vision heat maps},
volume = {109},
journal = {American journal of botany},
doi = {10.1002/ajb2.1842}
}

%%============================================================================%%
%% while using chicago reference style, both abbreviated and expanded form of %%
%% author name format is acceptable. Refer below example for expanded form    %%
%%============================================================================%%

%%  author		= "{Cameron, Deborah}", - single author
%%  author		= "{Saito, Yukio} and {Hyuga, Hiroyuki}", - double author 

%%======================================%%
%% Example for author names with suffix %%
%%======================================%%

%%  author		= "{Price, R. A. Jr} and {Curry, N. {III}} and McCann, K. E. and 
%%					Fielding, J. L. and {Abercrombie, E. Jr}",
