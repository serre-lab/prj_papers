%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%======================================================%%
%% to compile with pdflatex/xelatex use pdflatex option %%
%%======================================================%%

%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%\documentclass[sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
\documentclass[pdflatex,sn-mathphys,iicol]{sn-jnl}% Math and Physical Sciences Reference Style
%%\documentclass[sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
%%\documentclass[sn-vancouver]{sn-jnl}% Vancouver Reference Style
%%\documentclass[sn-apa]{sn-jnl}% APA Reference Style
%%\documentclass[sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style
%%\documentclass[sn-standardnature]{sn-jnl}% Standard Nature Portfolio Reference Style
%%\documentclass[default]{sn-jnl}% Default
%%\documentclass[default,iicol]{sn-jnl}% Default with double column layout

%%%% Standard Packages
%%<additional latex packages if required can be included here>
%%%%

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published 
%%%%  by Springer Nature. The guidance has been prepared in partnership with 
%%%%  production teams to conform to Springer Nature technical requirements. 
%%%%  Editorial and presentation requirements differ among journal portfolios and 
%%%%  research disciplines. You may find sections in this template are irrelevant 
%%%%  to your work and are empowered to omit any such section if allowed by the 
%%%%  journal you intend to submit to. The submission guidelines and policies 
%%%%  of the journal take precedence. A detailed User Manual is available in the 
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

\jyear{2021}%

%% as per the requirement new theorem styles can be included as shown below
\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{proposition}[theorem]{Proposition}% 
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%

\newcommand{\felipe}[1]{{\color{orange}[felipe]: #1}}
\newcommand{\fel}[1]{{\color{purple}[fel]: #1}}

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

\iffalse

and ai for paleo identification of paleobotany --> peter
3rd para --> challenge for fossil leaves, do not have enough samples for families and no sample for most (annotated) --> figure 1 (s) 
closest to fossils are clear leaves --> doesnt work, training on leaves and testing on fossils
novel use of triplet loss --> bridging two domains and evaluate 
levarage gans to generate synthetic fossils 

bunch of synthtic fossils --> figure 1
triplet --> supplementary information 
figure : tsne embeddings --> triplet loss random samples and --> all classes, 19 families, both fossils and clear leaves 

train and test --> acc --> one leave on out + final systems trained on everything and evaluate on 19. 

demonstration to show that --> assist the classification of unknown fossils 

figure 3: feature visualization and attributions 

*** using ibm nodes --> high res and high memory

cleaning up dataset --> steps followed

\fi

\begin{document}

\title[Article Title]{Article Title}

%%=============================================================%%
%% Prefix	-> \pfx{Dr}
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% NatureName	-> \tanm{Poet Laureate} -> Title after name
%% Degrees	-> \dgr{MSc, PhD}
%% \author*[1,2]{\pfx{Dr} \fnm{Joergen W.} \spfx{van der} \sur{Ploeg} \sfx{IV} \tanm{Poet Laureate} 
%%                 \dgr{MSc, PhD}}\email{iauthor@gmail.com}
%%=============================================================%%

\author*[1]{\fnm{Iva\'n Felipe} \sur{Rodr\'iguez }}\email{ivan.rodriguez5@brown.edu}
\equalcont{These authors contributed equally to this work.}
\author*[1,2]{\fnm{Thomas} \sur{Fel}} \email{thomas\_fel@brown.edu}
\equalcont{These authors contributed equally to this work.}
\author[1,2]{\fnm{Mohit} \sur{Vaishnav}} \email{mohit.vaishnav@univ-toulouse.fr}
\equalcont{These authors contributed equally to this work.}


\affil*[1]{\orgdiv{Carney Institute for Brain Science, Dpt. of Cognitive Linguistic \& Psychological Sciences}, \orgname{Brown University}, \orgaddress{\city{Providence}, \postcode{02912}, \state{RI}, \country{USA}}}

\affil[2]{\orgdiv{Artificial and Natural Intelligence Toulouse Institute}, \orgname{Université de Toulouse}, \orgaddress{\city{Toulouse}, \postcode{31400}, \country{France}}}


%%==================================%%
%% sample for unstructured abstract %%
%%==================================%%

\abstract{

Determining leaf fossil families is a major biological challenge, and data availability is often limited.
Recent advances in deep learning -- as well as in explainability -- applied to the botany problem could allow the discovery of new rules and facilitate the identification of undetermined fossil families.

We have developed a deep learning model based on paleo-botany images, to classify fossil families among more than 
20 different classes with high accuracy.
We demonstrate through explainability tools that our model is able to help domain experts to identify new fossils as well as to give indications on new feature sets that could be used to determine the family of a fossil from an image.

Overall, this new interpretable neural network allows to classify with a high accuracy the family of a fossil among a large set of classes and can have a general application in the identification of other types of fossils.

}

%%================================%%
%% Sample for structured abstract %%
%%================================%%

% \abstract{\textbf{Purpose:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Methods:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Results:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Conclusion:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.}

\keywords{keyword1, Keyword2, Keyword3, Keyword4}

%%\pacs[JEL Classification]{D8, H51}

%%\pacs[MSC Classification]{35A01, 65L10, 65L12, 65L20, 65L70}

\maketitle

%%% 
%%% Nature Guideline
%%%

% An uninterrupted page of text contains about 1250 words.
% A typical 6-page Article contains about 2,500 words of text and, additionally, 4 modest display items (figures and/or tables) with brief legends, reference list and online-only methods section if applicable. A composite figure (with several panels) usually needs to take about half a page, equivalent to about 600 words, in order for all the elements to be visible (see section 5.9 for instructions on sizing figures).

% Nature requires authors to specify the contribution made by their co-authors in the end notes of the paper. If authors regard it as essential to indicate that two or more co-authors are equal in status, they may be identified by an asterisk symbol with the caption ‘These authors contributed equally to this work’ immediately under the address list.

% The ‘Methods’ section is in the main text file, following the figure legends. This Methods section will appear in the PDF and in the full-text (HTML) version of the paper online, but will not appear in the printed issue. The Methods section should be written as concisely as possible but should contain all elements necessary to allow interpretation and replication of the results. As a guideline, the Methods section does not typically exceed 3,000 words. 

% References are each numbered, ordered sequentially as they appear in the text, tables, boxes, figure legends, Methods, Extended Data tables and Extended Data figure legends.
% When cited in the text, reference numbers are superscript, not in brackets unless they are likely to be confused with a superscript number.
% As a guideline, Articles allow up to 50 references in the main text if needed and within the average page budget. Only one publication can be listed for each number. Additional references for Methods or Supplementary Information are not included in this count.
% Only articles that have been published or accepted by a named publication, or that have been uploaded to a recognized preprint server (for example, arXiv, bioRxiv), should be in the reference list; papers in preparation should be mentioned in the text with a list of authors (or initials if any of the authors are co-authors of the present contribution).
% All authors should be included in reference lists unless there are more than five, in which case only the first author should be given, followed by ‘et al.’.
% Detailed descriptions of methods already published should be avoided; a reference number can be provided to save space, with any new addition or variation stated.
% The Methods section should be subdivided by short bold headings referring to methods used and we encourage the inclusion of specific subsections for statistics, reagents and animal models. If further references are included in this section their numbering should continue from the end of the last reference number in the rest of the paper and they are listed after the Methods section.
% Please provide separate Data Availability and Code Availability statements after the main text statements and before the Extended Data legends; detailed guidance can be found in our data availability and data citations policy. Certain data types must be deposited in an appropriate public structured data depository (details are available here), and the accession number(s) provided in the manuscript. Full access is required at the time of publication. Should full access to data be required for peer review, authors must provide it.
% The Methods section cannot contain figures or tables (essential display items should be included in the Extended Data or exceptionally in the Supplementary Information).

\section{Introduction}\label{sec1}

\fel{(1) Artificial Intelligence for PaleoBotany (we need Peter here).}

With advances in botanical research technology, the ability to collect and store leaf data has increased significantly. Specifically, in the case of plant family identification, expert annotation has allowed the creation of plant databases that have led to the research and evaluation of important characteristics for each family. However, the case of fossilized plants remains challenging, due to the still limited amount of data and their identification is often more complex than that of leaves. 

In parallel, several works have shown the relevance of deep learning models, especially when applied to botany. In paleo-botany, the explainability of predictive models is crucial, as the properties that contribute to the predictive capabilities of the model can not only enlighten experts, but also provide information about the underlying biological processes to stimulate research to find new relationships between different families \fel{(really weak, I need peter here haha)}.

Statistical learning using linear models such as logistic regression are generally an interpretable method but at the cost of lower predictive performance, and the rules underlying computer vision problems for leaf recognition require complex rules.
On the other hand, deep learning models are able to learn such complex rules which often lead them to overfit, unless they are properly guided during training, and have enough data.
In addition, a large number of efforts to improve the interpretability of neural network models are now emerging that reveal the complex and interesting mechanisms of these models, allowing to understand how the model processes information and makes decisions.

We have developed a deep-learning-based computer-vision system for identifying extant-leaf images to botanical family, using a new image database of cleared, x-rayed, and fossil leaves consisting mostly of angiosperms. Here, we describe novel methods to extend the system for the identification of fossil leaves at the family level. The challenge for the development of computer vision systems, which normally rely on tens of thousands to millions of training images, is that comparatively few vetted fossil leaf samples are available to train the system; the majority of angiosperm families have no reliable leaf fossils. Here, we describe the development of computer-vision methods to successfully transfer machine knowledge from cleared to fossil leaves. Our approach leverages so-called image-to-image translation methods (conditional cycleGAN) to generate synthetic fossils by learning mappings between one image distribution (cleared leaves) and another (fossil leaves). We use these methods to augment our real-image database with a high quantity and phylogenetic diversity of synthetic samples not available from real fossils alone. 

We train a deep neural network architecture using both real and synthetic images to learn a joint representation for known families of cleared leaves and fossils. We evaluate the network’s accuracy in multiple scenarios. First, we demonstrate high classification accuracy for cleared leaves. We further find a high (albeit lower) accuracy for real fossil leaves. This is presumably due to the comparatively much smaller number of fossil vs. cleared-leaf samples, combined with taphonomic signal loss. We further evaluate the ability of the proposed methods to generalize to real fossils of families for which no real fossil was presented during training. We use a leave-one-family-out cross-validation approach whereby real leaf fossils are used for training for all families but one (i.e., only synthetic samples are available for the test family). We report significantly above-chance classification accuracy in this scenario. A study using explainability methods is carried out in order to identify some of the strategies used for the classification. Our results strongly suggest that AI methods will provide significant assistance to paleobotanists with the identification of leaf fossils.

\section{Data Processing}
% Mohit 
Herbarium sheets are labeled with various information on it like name of the taxon, geographical location where it is collected from or the name of the team or person who collected it. These annotations are also made to correct or update the information. In addition to these labels, these specimens also contains institutional labels, stamps and bar-code corresponding to the institutional database. Having all these information on the herbarium sheet is very much beneficial on the one hand for humans to keep track of the changes, however they also push the neural network models to focus on these shortcuts instead looking for the right features to come to a decision. In order to avoid this problem, we blurred out these regions. We used a pretrained text detector model, CRAFT \cite{baek2019character} which detects the text area by exploring each character and affinity between them. Once the text areas are selected, we applied heavy blurring over those to prevent the network from reading those particular area. We first applied mean blurring to the area followed by Gaussian blurring with added noise and finally smooth alpha to blend this to the original image. We kept a high confidence score to detect text in order to prevent the false positives inside the leaf.   
% Write about the labels on the herbarium sheets --> what do they represents --> name of the taxon, geographical location where it is collected from, or person or the team who collected it. Annotation labels are usually added to correct or update the information. Specimen also has institutional labels, stamps, barcode corresponding to institutional database. --> we need to blur so that model is forced to learn about leaves/fossils instead the shortcuts obtained from text labels. We used a pretrained CRAFT \cite{baek2019character} text detector to detect text in these images. Outputs --> bounding box around detected text. This resulting regions were heavily blurred. First mean blur --> gaussian blur with added noise, and smooth alpha to blend into the original image. Tuned to have high specificity to avoid unnecessarily blurring plant parts even if there are images where the parts of labels are missed. Text and scale were also blurred in many images.     

% Thomas
% i think that should be added in the flow of the text, I didn't saw any Nature's paper with a dedicated data process section 

\section{Results}

\fel{(3) Our method: we leverage (a) GAN and (b) Triplet Loss.}

\fel{(3)(a) Look at our beautiful fake fossils.}
We have developed a Deep Learning model capable of transforming a leaf image to the same fossil image (see Fig.1) in order to create an artificial fossil dataset and train a deep learning model capable of classification on it (see Fig.2).

\fel{(3)(b) Look at our beautiful embedding (with / without triplet).}
A set of 30000 leaf images were used to create a GAN cycle model, the fossil images output from the gan are then given to the classifier for training. The classifier uses a loss triplet that allows it to use the leaves and the fossils at the same time by forcing the representation (state of the neurons) to be close for the same image and its fake fossil. In all, the triplet loss was trained on 1000 images (see Methods, see supplementary), divided into 80\% training, 10\% test and 10\% validation images to predict among 19 classes. The triplet model largely outperformed a model trained on leaves only (accuracy=0.9 vs accuracy = 0.1, supplementary table 2). In addition, we evaluated with a leave-one-out method in order to ... .

\fel{(4) We demonstrate how the model help expert to identify unknow fossil.}
In order to understand the interactions and characteristics that lead the model to make a decision, we studied the explainability maps after training (see Fig3).


\section{Conclusion}


\newpage
\section{Methods}

There are two main parts of our algorithm. First we perform cross domain adaptation via a conditional cycleGAN \cite{CycleGAN2017},\cite{isola2017image} and second we perform a feature learning and classification using a standard classification architecture regularized with a cross-domain triplet. 

\subsection{Cross Domain Adaptation}\label{sec2.1}
The cross domain adaptation takes inspiration for the usual CycleGAN, where we build two mappings between the fossil domain (X) and the extant leaves domain (Y) in the following way, $G: X \rightarrow Y$ and $F: Y \rightarrow X$ . Since our end goal is not only to generate fossilized looking samples but to encode family traits that can be used for classification, we use a triplet regularizer (T) to enforce proximity between elements of the same family and higher distance from different families. 

The triplet regularizer is train at every cycle of the GAN, ensuring that at the source (T(X)), the target (T(Y)), and the transformations (T(G(X)),T(F(Y))) the latent structure is keeping relevant information for  classification. 

The objective function then can be written as: 

\begin{align}
    \mathcal{L}(G,F,D_X,D_Y) &= \mathcal{L}_{GAN}(G,D_Y,X,Y)  
    \\&+ \mathcal{L}_{GAN}(G,D_X,Y,X) 
    \\&+ \lambda_1 \mathcal{L}(G,F) 
    \\&+ \lambda_2 \mathcal{L}(T,G,F,X,Y)
\end{align}

\subsection{Cross-Domain Classification}\label{sec2.2}

Following \cite{taha2020boosting} we use a two-headed architecture using a softmax and a triplet loss as a regularizer. We introduce a cross domain triplet, that not only uses the class to perform the sampling but uses the information of the domains (fossil or extant)  to ensure that in the embedding there is   local and global the structure. 

In this way, we formulate our triplet loss in the following way: 

\begin{align}
    \mathcal{L}_{trixdomain}= \frac{1}{b}\sum_{i=1}^{b}[(D(a_{i,x},p_{i,x})-D(a_{i,x}x,n_{i,x}) + m)]
\end{align}

Where b is the number of samplings and D is a distance function that acts over an anchor (a) a positive sample (p) and a negative sample (n) with a fixed margin (m); with $x \in \{X,Y\}$ the two domains that we are considering. 

Then the total loss function on which this network is trained can be written as: 
\begin{equation}
    \mathcal{L} = \mathcal{L}_{softmax} + \lambda \mathcal{L}_{trixdomain}
\end{equation}

Finally, we added the synthetic images created in the first step to account for those classes where little or no  data is available. 

\subsection{Metrics}

Our overall interest is to use the transfer between domains to populate such domains where little or no data is available, in order to improve classification accuracy by learning closeness between families.   In total we have 19 families that are shared between domains (leafs and fossils) with  enough samples to train an evaluate. We propose to use a leave one out scheme to evaluate our methods. 

In the leave one out scheme, we test in all the available samples for a given family while adding at training time the samples obtained from the cyclegan explained in section 2. 


% Please add the following required packages to your document preamble:
% \usepackage{multirow}

\iffalse 

    \begin{table}[]
    \centering
    \begin{tabular}{|l|l|lll|lll|}
    \hline
     &
      \textbf{Loss} &
      \multicolumn{3}{l|}{\textbf{No Triplet}} &
      \multicolumn{3}{l|}{\textbf{Xdomain}} \\ \hline
    \textbf{Training} &
      Top/Shot &
      \multicolumn{1}{l|}{1} &
      \multicolumn{1}{l|}{3} &
      5 &
      \multicolumn{1}{l|}{1} &
      \multicolumn{1}{l|}{3} &
      5 \\ \hline
    \multirow{4}{*}{\textbf{Imagenet}} &
      0 &
      \multicolumn{1}{l|}{0.38} &
      \multicolumn{1}{l|}{0.46} &
      0.55 &
      \multicolumn{1}{l|}{0.39} &
      \multicolumn{1}{l|}{0.45} &
      0.57 \\ \cline{2-8} 
     &
      1 &
      \multicolumn{1}{l|}{0.43} &
      \multicolumn{1}{l|}{0.5} &
      0.6 &
      \multicolumn{1}{l|}{0.42} &
      \multicolumn{1}{l|}{0.49} &
      0.60 \\ \cline{2-8} 
     &
      5 &
      \multicolumn{1}{l|}{0.46} &
      \multicolumn{1}{l|}{0.58} &
      0.69 &
      \multicolumn{1}{l|}{0.49} &
      \multicolumn{1}{l|}{0.71} &
      0.79 \\ \cline{2-8} 
     &
      10 &
      \multicolumn{1}{l|}{0.55} &
      \multicolumn{1}{l|}{0.69} &
      0.79 &
      \multicolumn{1}{l|}{0.58} &
      \multicolumn{1}{l|}{0.72} &
      0.81 \\ \hline
    \multicolumn{1}{|c|}{\multirow{4}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Imagenet \\ +\\ \\ GAN\end{tabular}}}} &
      0 &
      \multicolumn{1}{l|}{0.34} &
      \multicolumn{1}{l|}{0.41} &
      0.51 &
      \multicolumn{1}{l|}{0.39} &
      \multicolumn{1}{l|}{0.44} &
      0.60 \\ \cline{2-8} 
    \multicolumn{1}{|c|}{} &
      1 &
      \multicolumn{1}{l|}{0.35} &
      \multicolumn{1}{l|}{0..5} &
      0.6 &
      \multicolumn{1}{l|}{0.41} &
      \multicolumn{1}{l|}{0.51} &
      0.65 \\ \cline{2-8} 
    \multicolumn{1}{|c|}{} &
      5 &
      \multicolumn{1}{l|}{0.44} &
      \multicolumn{1}{l|}{0.64} &
      0.79 &
      \multicolumn{1}{l|}{0.41} &
      \multicolumn{1}{l|}{0.75} &
      0.8 \\ \cline{2-8} 
    \multicolumn{1}{|c|}{} &
      10 &
      \multicolumn{1}{l|}{0.51} &
      \multicolumn{1}{l|}{0.74} &
      0.87 &
      \multicolumn{1}{l|}{0.54} &
      \multicolumn{1}{l|}{\textbf{0.77}} &
      \textbf{0.88} \\ \hline
    \multirow{4}{*}{\textbf{Pretrained}} &
      0 &
      \multicolumn{1}{l|}{} &
      \multicolumn{1}{l|}{} &
       &
      \multicolumn{1}{l|}{} &
      \multicolumn{1}{l|}{} &
       \\ \cline{2-8} 
     &
      1 &
      \multicolumn{1}{l|}{} &
      \multicolumn{1}{l|}{} &
       &
      \multicolumn{1}{l|}{} &
      \multicolumn{1}{l|}{} &
       \\ \cline{2-8} 
     &
      5 &
      \multicolumn{1}{l|}{} &
      \multicolumn{1}{l|}{} &
       &
      \multicolumn{1}{l|}{} &
      \multicolumn{1}{l|}{} &
       \\ \cline{2-8} 
     &
      10 &
      \multicolumn{1}{l|}{} &
      \multicolumn{1}{l|}{} &
       &
      \multicolumn{1}{l|}{} &
      \multicolumn{1}{l|}{} &
       \\ \hline
    \end{tabular}
    \caption{ Comparison across Loss functions and training datasets}
    \label{tab:my-table}
    \end{table}

\fi

\bigskip
%%=============================================%%
%% For presentation purpose, we have included  %%
%% \bigskip command. please ignore this.       %%
%%=============================================%%


% \begin{program}
% \BEGIN \\ %
%   \FOR i:=1 \TO 10 \STEP 1 \DO
%      |expt|(2,i); \\ |newline|() \OD %
% \rcomment{Comments will be set flush to the right margin}
% \WHERE
% \PROC |expt|(x,n) \BODY
%           z:=1;
%           \DO \IF n=0 \THEN \EXIT \FI;
%              \DO \IF |odd|(n) \THEN \EXIT \FI;
% \COMMENT{This is a comment statement};
%                 n:=n/2; x:=x*x \OD;
%              \{ n>0 \};
%              n:=n-1; z:=z*x \OD;
%           |print|(z) \ENDPROC
% \END
% \end{program}


% \begin{algorithm}
% \caption{Calculate $y = x^n$}\label{algo1}
% \begin{algorithmic}[1]
% \Require $n \geq 0 \vee x \neq 0$
% \Ensure $y = x^n$ 
% \State $y \Leftarrow 1$
% \If{$n < 0$}\label{algln2}
%         \State $X \Leftarrow 1 / x$
%         \State $N \Leftarrow -n$
% \Else
%         \State $X \Leftarrow x$
%         \State $N \Leftarrow n$
% \EndIf
% \While{$N \neq 0$}
%         \If{$N$ is even}
%             \State $X \Leftarrow X \times X$
%             \State $N \Leftarrow N / 2$
%         \Else[$N$ is odd]
%             \State $y \Leftarrow y \times X$
%             \State $N \Leftarrow N - 1$
%         \EndIf
% \EndWhile
% \end{algorithmic}
% \end{algorithm}
% \bigskip
%%=============================================%%
%% For presentation purpose, we have included  %%
%% \bigskip command. please ignore this.       %%
%%=============================================%%



\backmatter

\bmhead{Supplementary information}

If your article has accompanying supplementary file/s please state so here. 

Authors reporting data from electrophoretic gels and blots should supply the full unprocessed scans for key as part of their Supplementary information. This may be requested by the editorial team/s if it is missing.

Please refer to Journal-level guidance for any specific requirements.

\bmhead{Acknowledgments}

Acknowledgments are not compulsory. Where included they should be brief. Grant or contribution numbers may be acknowledged.

Please refer to Journal-level guidance for any specific requirements.

% \section*{Declarations}

% Some journals require declarations to be submitted in a standardised format. Please check the Instructions for Authors of the journal to which you are submitting to see if you need to complete this section. If yes, your manuscript must contain the following sections under the heading `Declarations':

% \begin{itemize}
% \item Funding
% \item Conflict of interest/Competing interests (check journal-specific guidelines for which heading to use)
% \item Ethics approval 
% \item Consent to participate
% \item Consent for publication
% \item Availability of data and materials
% \item Code availability 
% \item Authors' contributions
% \end{itemize}

% \noindent
% If any of the sections are not relevant to your manuscript, please include the heading and write `Not applicable' for that section. 

% %%===================================================%%
% %% For presentation purpose, we have included        %%
% %% \bigskip command. please ignore this.             %%
% %%===================================================%%
% \bigskip
% \begin{flushleft}%
% Editorial Policies for:

% \bigskip\noindent
% Springer journals and proceedings: \url{https://www.springer.com/gp/editorial-policies}

% \bigskip\noindent
% Nature Portfolio journals: \url{https://www.nature.com/nature-research/editorial-policies}

% \bigskip\noindent
% \textit{Scientific Reports}: \url{https://www.nature.com/srep/journal-policies/editorial-policies}

% \bigskip\noindent
% BMC journals: \url{https://www.biomedcentral.com/getpublished/editorial-policies}
% \end{flushleft}

\begin{appendices}

\section{Section title of first appendix}\label{secA1}

An appendix contains supplementary information that is not an essential part of the text itself but which may be helpful in providing a more comprehensive understanding of the research problem or it is information that is too cumbersome to be included in the body of the paper.

%%=============================================%%
%% For submissions to Nature Portfolio Journals %%
%% please use the heading ``Extended Data''.   %%
%%=============================================%%

%%=============================================================%%
%% Sample for another appendix section			       %%
%%=============================================================%%

%% \section{Example of another appendix section}\label{secA2}%
%% Appendices may be used for helpful, supporting or essential material that would otherwise 
%% clutter, break up or be distracting to the text. Appendices can consist of sections, figures, 
%% tables and equations etc.

\end{appendices}

%%===========================================================================================%%
%% If you are submitting to one of the Nature Portfolio journals, using the eJP submission   %%
%% system, please include the references within the manuscript file itself. You may do this  %%
%% by copying the reference list from your .bbl file, paste it into the main manuscript .tex %%
%% file, and delete the associated \verb+\bibliography+ commands.                            %%
%%===========================================================================================%%

\bibliography{sn-bibliography}% common bib file
%% if required, the content of .bbl file can be included here once bbl is generated
%%\input sn-article.bbl

%% Default %%
%%\input sn-sample-bib.tex%

\end{document}
